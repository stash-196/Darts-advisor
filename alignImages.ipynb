{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['/private/var/folders/m5/zysgnrhs03d3hlm12zmmtvh80000gn/T/4af174a2-7d4c-4ccf-b9f0-88c18202f1d1', '/Users/tomonagasutashu/.vscode/extensions/ms-python.python-2020.1.57204/pythonFiles', '/Users/tomonagasutashu/.vscode/extensions/ms-python.python-2020.1.57204/pythonFiles/lib/python', '/Users/tomonagasutashu/anaconda3/lib/python37.zip', '/Users/tomonagasutashu/anaconda3/lib/python3.7', '/Users/tomonagasutashu/anaconda3/lib/python3.7/lib-dynload', '', '/Users/tomonagasutashu/anaconda3/lib/python3.7/site-packages', '/Users/tomonagasutashu/anaconda3/lib/python3.7/site-packages/aeosa', '/Users/tomonagasutashu/anaconda3/lib/python3.7/site-packages/IPython/extensions', '/Users/tomonagasutashu/.ipython']\n"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import constraints\n",
    "import detect_diff\n",
    "\n",
    "import importlib\n",
    "importlib.reload(constraints)\n",
    "importlib.reload(detect_diff)\n",
    "\n",
    "from constraints import SCORES\n",
    "from detect_diff import getDifference\n",
    "\n",
    "import sys \n",
    "print(sys.path)\n",
    "\n",
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading reference image :  resources/shomen_cropped_inside_eraced.jpg\nReading image to align :  resources/0111.2.jpg\nAligning images ...\nSaving aligned image :  outputs/aligned0111.1.jpg\nEstimated homography : \n [[ 7.32286451e-01 -6.83339206e-02 -1.43938608e+02]\n [-1.23298981e-01  8.38732064e-01 -2.05728946e+01]\n [-5.02519994e-04  2.24377073e-04  1.00000000e+00]]\n"
    }
   ],
   "source": [
    "def alignImages(im1, im2):\n",
    " \n",
    "  # Convert images to grayscale\n",
    "  im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "  im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "  # Detect ORB features and compute descriptors.\n",
    "  orb = cv2.ORB_create(MAX_FEATURES)\n",
    "  keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "  keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "   \n",
    "  # Match features.\n",
    "  matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "  matches = matcher.match(descriptors1, descriptors2, None)\n",
    "   \n",
    "  # Sort matches by score\n",
    "  matches.sort(key=lambda x: x.distance, reverse=False)\n",
    " \n",
    "  # Remove not so good matches\n",
    "  numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "  matches = matches[:numGoodMatches]\n",
    " \n",
    "  # Draw top matches\n",
    "  imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "  cv2.imwrite(\"matches.jpg\", imMatches)\n",
    "   \n",
    "  # Extract location of good matches\n",
    "  points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "  points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    " \n",
    "  for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "   \n",
    "  # Find homography\n",
    "  h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    " \n",
    "  # Use homography\n",
    "  height, width, channels = im2.shape\n",
    "  im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "   \n",
    "  return im1Reg, h\n",
    " \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Read reference image\n",
    "    refFilename = \"resources/shomen_cropped_inside_eraced.jpg\"\n",
    "    print(\"Reading reference image : \", refFilename)\n",
    "    imReference = cv2.imread(refFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Read image to be aligned\n",
    "    imFilename = \"resources/0111.2.jpg\"\n",
    "    print(\"Reading image to align : \", imFilename);  \n",
    "    im = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    print(\"Aligning images ...\")\n",
    "    # Registered image will be resotred in imReg. \n",
    "    # The estimated homography will be stored in h. \n",
    "    imReg, h = alignImages(im, imReference)\n",
    "\n",
    "    h_inv = np.linalg.inv(h)\n",
    "\n",
    "    # Write aligned image to disk. \n",
    "    outFilename = \"outputs/aligned0111.1.jpg\"\n",
    "    print(\"Saving aligned image : \", outFilename); \n",
    "    cv2.imwrite(outFilename, imReg)\n",
    "\n",
    "    # Print estimated homography\n",
    "    print(\"Estimated homography : \\n\",  h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6f7599e89a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use inverse homography\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mh_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'im2' is not defined"
     ]
    }
   ],
   "source": [
    "  # Use inverse homography\n",
    "  height, width, channels = im2.shape\n",
    "  h_inv = np.linalg.inv(h)\n",
    "  img_back = cv2.warpPerspective(im1, h_inv, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading reference image :  resources/0111.0.jpg\nReading reference image :  resources/0111.2.jpg\n(720, 1080, 3) (720, 1080)\nSaving detected difference image :  outputs/applymask.jpg\nSaving detected difference image :  outputs/diff.jpg\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Read background image\n",
    "    bcgFilename = \"resources/0111.0.jpg\"\n",
    "    print(\"Reading reference image : \", bcgFilename)\n",
    "    img_bcg = cv2.imread(bcgFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Read new image\n",
    "    newFilename = \"resources/0111.2.jpg\"\n",
    "    print(\"Reading reference image : \", newFilename)\n",
    "    img_new = cv2.imread(newFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    gray_bcg = cv2.cvtColor(img_bcg, cv2.COLOR_BGR2GRAY)\n",
    "    gray_new = cv2.cvtColor(img_new, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    diff_thred, gray1, gray2, diff = getDifference(gray_bcg, gray_new)\n",
    "\n",
    "    print(img_new.shape, diff_thred.shape)\n",
    "    # apply mask\n",
    "    dst = np.empty_like(img_new)\n",
    "    dst[:,:,0] = cv2.bitwise_and(img_new[:,:,0], diff_thred)\n",
    "    dst[:,:,1] = cv2.bitwise_and(img_new[:,:,1], diff_thred)\n",
    "    dst[:,:,2] = cv2.bitwise_and(img_new[:,:,2], diff_thred)\n",
    "\n",
    "    # Write applied mask to disk.\n",
    "    outFilename = \"outputs/applymask.jpg\"\n",
    "    print(\"Saving detected difference image : \", outFilename)\n",
    "    cv2.imwrite(outFilename, dst)\n",
    "\n",
    "    # Write detected difference to disk.\n",
    "    outFilename = \"outputs/diff.jpg\"\n",
    "    print(\"Saving detected difference image : \", outFilename)\n",
    "    cv2.imwrite(outFilename, diff_thred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda82db9c31c1e5471a8f872ea293d8c38f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}