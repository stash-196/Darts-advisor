{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading reference image :  resources/shomen_cropped.jpg\ncreating Score Description...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Saving aligned image :  outputs/draw_board.jpg\nReading reference image :  resources/shomen_cropped.jpg\ncreating Score Description...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Saving aligned image :  outputs/draw_board.jpg\n"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import constraints\n",
    "import detect_diff\n",
    "import draw_dartboard\n",
    "import board_config as cfg\n",
    "\n",
    "import importlib\n",
    "importlib.reload(constraints)\n",
    "importlib.reload(detect_diff)\n",
    "importlib.reload(draw_dartboard)\n",
    "importlib.reload(cfg)\n",
    "\n",
    "from constraints import SCORES\n",
    "from detect_diff import getDifference\n",
    "from draw_dartboard import draw_regions\n",
    "\n",
    "import sys \n",
    "# print(sys.path)\n",
    "\n",
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading reference image :  resources/shomen_cropped_inside_eraced.jpg\nReading image to align :  resources/0111.2.jpg\nAligning images ...\nSaving aligned image :  outputs/aligned0111.1.jpg\nEstimated homography : \n [[ 7.32286451e-01 -6.83339206e-02 -1.43938608e+02]\n [-1.23298981e-01  8.38732064e-01 -2.05728946e+01]\n [-5.02519994e-04  2.24377073e-04  1.00000000e+00]]\n"
    }
   ],
   "source": [
    "def alignImages(im1, im2):\n",
    " \n",
    "  # Convert images to grayscale\n",
    "  im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "  im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "  # Detect ORB features and compute descriptors.\n",
    "  orb = cv2.ORB_create(MAX_FEATURES)\n",
    "  keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "  keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "   \n",
    "  # Match features.\n",
    "  matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "  matches = matcher.match(descriptors1, descriptors2, None)\n",
    "   \n",
    "  # Sort matches by score\n",
    "  matches.sort(key=lambda x: x.distance, reverse=False)\n",
    " \n",
    "  # Remove not so good matches\n",
    "  numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "  matches = matches[:numGoodMatches]\n",
    " \n",
    "  # Draw top matches\n",
    "  imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "  cv2.imwrite(\"matches.jpg\", imMatches)\n",
    "   \n",
    "  # Extract location of good matches\n",
    "  points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "  points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    " \n",
    "  for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "   \n",
    "  # Find homography\n",
    "  h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    " \n",
    "  # Use homography\n",
    "  height, width, channels = im2.shape\n",
    "  im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "   \n",
    "  return im1Reg, h\n",
    " \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Read reference image\n",
    "    refFilename = \"resources/shomen_cropped_inside_eraced.jpg\"\n",
    "    print(\"Reading reference image : \", refFilename)\n",
    "    imReference = cv2.imread(refFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Read image to be aligned\n",
    "    imFilename = \"resources/0111.2.jpg\"\n",
    "    print(\"Reading image to align : \", imFilename);  \n",
    "    im = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    print(\"Aligning images ...\")\n",
    "    # Registered image will be resotred in imReg. \n",
    "    # The estimated homography will be stored in h. \n",
    "    imReg, h = alignImages(im, imReference)\n",
    "\n",
    "    h_inv = np.linalg.inv(h)\n",
    "\n",
    "    # Write aligned image to disk. \n",
    "    outFilename = \"outputs/aligned0111.1.jpg\"\n",
    "    print(\"Saving aligned image : \", outFilename); \n",
    "    cv2.imwrite(outFilename, imReg)\n",
    "\n",
    "    # Print estimated homography\n",
    "    print(\"Estimated homography : \\n\",  h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e01b3f717268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use inverse homography\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mh_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimg_back_to_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_bcg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_new' is not defined"
     ]
    }
   ],
   "source": [
    "  # Use inverse homography\n",
    "  h_inv = np.linalg.inv(h)\n",
    "  height, width, channels = img_new.shape\n",
    "  img_back_to_new = cv2.warpPerspective(img_bcg, h_inv, (width, height))\n",
    "\n",
    "  # Write inv homo to disk.\n",
    "  outFilename = \"outputs/inv.homo.jpg\"\n",
    "  print(\"Saving detected difference image : \", outFilename)\n",
    "  cv2.imwrite(outFilename, img_back_to_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading reference image :  resources/0111.0.jpg\nReading reference image :  resources/0111.2.jpg\nuint8\n(720, 1080)\n"
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/median_blur.dispatch.cpp:283: error: (-215:Assertion failed) (ksize % 2 == 1) && (_src0.dims() <= 2 ) in function 'medianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3078e13634bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgray_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdiff_thred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_bcg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_thred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/school-workspace/prokenB/Darts-advisor/detect_diff.py\u001b[0m in \u001b[0;36mgetDifference\u001b[0;34m(gray1, gray2)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_thred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_thred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdiff_thred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_thred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdiff_thred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/median_blur.dispatch.cpp:283: error: (-215:Assertion failed) (ksize % 2 == 1) && (_src0.dims() <= 2 ) in function 'medianBlur'\n"
     ]
    }
   ],
   "source": [
    "    # Read background image\n",
    "    bcgFilename = \"resources/0111.0.jpg\"\n",
    "    print(\"Reading reference image : \", bcgFilename)\n",
    "    img_bcg = cv2.imread(bcgFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Read new image\n",
    "    newFilename = \"resources/0111.2.jpg\"\n",
    "    print(\"Reading reference image : \", newFilename)\n",
    "    img_new = cv2.imread(newFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "    gray_bcg = cv2.cvtColor(img_bcg, cv2.COLOR_BGR2GRAY)\n",
    "    gray_new = cv2.cvtColor(img_new, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    diff_thred, gray1, gray2, diff = getDifference(gray_bcg, gray_new)\n",
    "\n",
    "    print(img_new.shape, diff_thred.shape)\n",
    "    # apply mask\n",
    "    dst = np.empty_like(img_new)\n",
    "    dst[:,:,0] = cv2.bitwise_and(img_new[:,:,0], diff_thred)\n",
    "    dst[:,:,1] = cv2.bitwise_and(img_new[:,:,1], diff_thred)\n",
    "    dst[:,:,2] = cv2.bitwise_and(img_new[:,:,2], diff_thred)\n",
    "\n",
    "    # dst = cv2.bitwise_and(diff, diff_thred)\n",
    "\n",
    "    # Write applied mask to disk.\n",
    "    outFilename = \"outputs/applymask.jpg\"\n",
    "    print(\"Saving detected difference image : \", outFilename)\n",
    "    cv2.imwrite(outFilename, dst)\n",
    "\n",
    "    # Write detected difference to disk.\n",
    "    outFilename = \"outputs/diff.jpg\"\n",
    "    print(\"Saving detected difference image : \", outFilename)\n",
    "    cv2.imwrite(outFilename, diff_thred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading reference image :  resources/shomen_black_background.jpg\nReading image to align :  resources/shomen_cropped.jpg\nAligning images ...\nSaving aligned image :  outputs/aligned_wc2bu.jpg\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask dartboard\n",
    "# Read reference image\n",
    "refFilename = \"resources/shomen_black_background.jpg\"\n",
    "print(\"Reading reference image : \", refFilename)\n",
    "img_black_uncropped = cv2.imread(refFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Read image to be aligned\n",
    "imFilename = \"resources/shomen_cropped.jpg\"\n",
    "print(\"Reading image to align : \", imFilename);  \n",
    "im_white_cropped = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "for i in range(im_white_cropped[0, :, 0].size):\n",
    "    for j in range(im_white_cropped[:, 0, 0].size):\n",
    "        r = np.linalg.norm((i - cfg.CENTER[0], j - cfg.CENTER[1]))\n",
    "        if r < cfg.DOUBLE_OUT_R:\n",
    "            im_white_cropped[j, i, 0] = 0\n",
    "            im_white_cropped[j, i, 1] = 0\n",
    "            im_white_cropped[j, i, 2] = 0\n",
    "\n",
    "print(\"Aligning images ...\")\n",
    "# Registered image will be resotred in imReg. \n",
    "# The estimated homography will be stored in h. \n",
    "imReg_wc2bu, h = alignImages(im_white_cropped, img_black_uncropped)\n",
    "\n",
    "# imReg_wc2bu = draw_regions(imReg_wc2bu, 200, 100)\n",
    "\n",
    "imReg_wc2bu_gray = cv2.cvtColor(imReg_wc2bu, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Write aligned image to disk. \n",
    "outFilename = \"outputs/aligned_wc2bu.jpg\"\n",
    "print(\"Saving aligned image : \", outFilename); \n",
    "cv2.imwrite(outFilename, imReg_wc2bu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Reading image :  resources/shomen.jpg\n0\n30\n45\n60\n(720, 1080)\nSaving image :  outputs/mask_shomen_regions.jpg\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read image\n",
    "imFilename = \"resources/shomen.jpg\"\n",
    "print(\"Reading image : \", imFilename);  \n",
    "im_shomen = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    "tx = 280\n",
    "ty = 50\n",
    "# im_shomen = draw_regions(im_shomen, tx, ty)\n",
    "center = (cfg.CENTER[0] + tx, cfg.CENTER[1] + ty)\n",
    "mask_shomen = im_shomen.copy()[:,:,0]\n",
    "for i in range(im_shomen[0, :, 0].size):\n",
    "    for j in range(im_shomen[:, 0, 0].size):\n",
    "        r_in = np.linalg.norm((i - center[0], j - center[1]))\n",
    "        # r_out = np.linalg.norm((i - center[0], j - center[1] - 70))\n",
    "        if r_in > cfg.DOUBLE_OUT_R:\n",
    "            # im_shomen[j, i, 0] = 0\n",
    "            # im_shomen[j, i, 1] = 0\n",
    "            # im_shomen[j, i, 2] = 0\n",
    "            mask_shomen[j, i] = 0\n",
    "        else: \n",
    "            mask_shomen[j, i] = 255\n",
    "for t in [0, 30, 45, 60]:\n",
    "    print(t)\n",
    "    for i in range(im_shomen[0, :, 0].size):\n",
    "        for j in range(im_shomen[:, 0, 0].size):\n",
    "            r = np.linalg.norm((i - center[0] - 100*np.cos(t/180*np.pi), j - center[1] + 100*np.sin(t/180*np.pi)))\n",
    "            if r < cfg.DOUBLE_OUT_R:\n",
    "                mask_shomen[j, i] = 255\n",
    "\n",
    "print(mask_shomen.shape)\n",
    "# Write image to disk. \n",
    "outFilename = \"outputs/mask_shomen_regions.jpg\"\n",
    "print(\"Saving image : \", outFilename); \n",
    "cv2.imwrite(outFilename, mask_shomen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda82db9c31c1e5471a8f872ea293d8c38f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}