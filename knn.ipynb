{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 2)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 画像１\n",
    "img1 = cv2.imread(\"materials/0104.1.jpg\")\n",
    "# 画像２\n",
    "img2 = cv2.imread(\"materials/shomen_cropped_inside_eraced.jpg\")\n",
    "# img2 = cv2.imread(\"0104.2.jpg\")\n",
    "\n",
    "# A-KAZE検出器の生成\n",
    "akaze = cv2.AKAZE_create()                                \n",
    "\n",
    "# 特徴量の検出と特徴量ベクトルの計算\n",
    "kp1, des1 = akaze.detectAndCompute(img1, None)\n",
    "kp2, des2 = akaze.detectAndCompute(img2, None)\n",
    "\n",
    "# Brute-Force Matcher生成\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# 特徴量ベクトル同士をBrute-Force＆KNNでマッチング\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "print(np.shape(matches))\n",
    "\n",
    "# データを間引きする\n",
    "\n",
    "good = []\n",
    "ratio = 0.5\n",
    "\n",
    "## ピクセル座標に変換\n",
    "### 選んだ4つの特徴点\n",
    "good1_pt = []\n",
    "good2_pt = []\n",
    "continue_ = False\n",
    "\n",
    "while(np.shape(good)[0] < 4 ):\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio * n.distance:\n",
    "#     print(\"ratio:\",ratio, \"good:\", np.shape(good))\n",
    "        \n",
    "            good1_pt = [list(map(int, kp1[m[0].queryIdx].pt)) for m in good]\n",
    "            \n",
    "            for g in good1_pt: \n",
    "                g_np = np.array(g)\n",
    "                m_np = np.array(list(map(int, kp1[m.queryIdx].pt)))\n",
    "                if np.linalg.norm(g_np - m_np) < 100:\n",
    "                    continue_ = True\n",
    "                    break\n",
    "                \n",
    "            if continue_ == True:\n",
    "                continue_ = False\n",
    "                continue_\n",
    "            else:\n",
    "                good.append([m])\n",
    "         \n",
    "        \n",
    "    ratio += 0.01\n",
    "    \n",
    "\n",
    "## ピクセル座標に変換\n",
    "### 元画像\n",
    "# img1_pt = [list(map(int, kp1[m[0].queryIdx].pt)) for m in good]\n",
    "# img2_pt = [list(map(int, kp2[m[0].trainIdx].pt)) for m in good]\n",
    "\n",
    "good1_pt = np.float32([list(map(int, kp1[m[0].queryIdx].pt)) for m in good])\n",
    "good2_pt = np.float32([list(map(int, kp2[m[0].trainIdx].pt)) for m in good])\n",
    "\n",
    "\n",
    "Mat = cv2.getPerspectiveTransform(good1_pt, good2_pt)\n",
    "\n",
    "# 対応する特徴点同士を描画\n",
    "img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, flags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像表示\n",
    "cv2.imshow('img', img3)\n",
    "\n",
    "# キー押下で終了\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# np.linalg.norm([])\n",
    "print(np.linalg.norm((np.array([0,0]) - np.array([3,4]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
